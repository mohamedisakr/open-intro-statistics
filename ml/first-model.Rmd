---
title: "First Machine Learning Model"
author: "Awesome Me"
date: "2023-05-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## load packages
```{r warning = F}
if(!require("pacman")) install.packages("pacman")
pacman::p_load(
  tidyverse,
  janitor,
  readxl,
  knitr,
  ggplot2,
  lubridate,
  arules,
  arulesViz,
  plyr,
  here,
  conflicted,
  RColorBrewer,
  skimr,
  psych,
  reshape2,
  DataExplorer,
  scales,
  boot,
  randomForest
)

```



## load dataset

```{r}
# https://www.kaggle.com/code/camnugent/introduction-to-machine-learning-in-r-tutorial



# melbourne_data = read_csv(here::here("data", "melb_data.csv")) %>% as_tibble()

# basedir <- here::here()
# basedir

housing = read_csv(here::here("housing.csv")) %>% as_tibble()
# melbourne_data = read_csv(here::here("melb_data.csv")) %>% as_tibble()


```

## inspect dataset structure 

```{r}

housing %>% colnames()  # list of column names
housing %>% nrow()  # how many rows are in data frame?
housing %>% dim()  # dimensions of the data frame?
housing %>% head()  # see the first 6 rows of data frame.  also tail()
housing %>% str()  # see list of columns and data types (numeric, character, etc)
housing %>% summary()  #Statistical summary of data.


```

## examining duplicate records -> for col1, col2, ...

```{r}

duplicated_rows <- housing %>% 
  get_dupes()

duplicated_rows

```


## remove temporary variables 
```{r}

rm(list = grep("^duplicated", ls(), value = TRUE))

```

## checking distinct for the whole df or single column
```{r}

n_distinct(housing) 


```

## checking for NAs
```{r}
sum(is.na(housing))

```

## drop all na values (missing values)
```{r}

housing <- housing %>% drop_na()

```


## convert column data type
```{r}


```

## delete column(s)
```{r}


```



## normalization
```{r}


```


## analyze if there are any correlations between variables
```{r}
# density plot
housing %>% plot_density(ncol = 4, ggtheme = theme_minimal())

# correlation plot
corPlot(housing[, 2:7], upper = FALSE, scale = FALSE, main = "Correlation Sales")

```

## selecting prediction target
```{r}
# y = housing$Price
# y %>% str

```

## selecting features 
```{r}

# housing_features <- c('Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude')
# 
# X = housing[housing_features]
# 
# X %>% str()
# 
# X %>% summary()
# 
# X %>% head()

```
```{r}

par(mfrow=c(2,5))

```

```{r}
colnames(housing)

```

```{r}

ggplot(data = melt(housing), mapping = aes(x = value)) + 
    geom_histogram(bins = 30) + facet_wrap(~variable, scales = 'free_x')

```

## fill missing values for total_bedrooms with its median
```{r}

housing$total_bedrooms[is.na(housing$total_bedrooms)] <- 
  median(housing$total_bedrooms , na.rm = TRUE)

sum(is.na(housing$total_bedrooms))

```
## fix the total columns - make them means
```{r}
housing$mean_bedrooms = housing$total_bedrooms/housing$households
housing$mean_rooms = housing$total_rooms/housing$households

drops = c('total_bedrooms', 'total_rooms')

housing = housing[ , !(names(housing) %in% drops)]

```

## list ocean_proximity values
```{r}
housing %>% group_by(ocean_proximity) %>% 
  # dplyr::filter(n() > 1) %>% 
  # na.omit() %>% # drop rows containing missing values
  dplyr::summarize(count = n()) %>% 
  dplyr::arrange(desc(count))

```
## convert char to categorical
```{r}

str(housing$ocean_proximity)

housing <- housing %>% dplyr::mutate(ocean_proximity = as.factor(ocean_proximity))

str(housing$ocean_proximity)

```
## long to wide 
### use pivot_wider converting categorial variables to boolean
```{r}
cat_housing <- housing %>% 
  # select column "ocean_proximity" for cat_housing
    # select(ocean_proximity) %>%
# create columns "val" and "ID" (R needs a unique identifier for an anchor when pivoting)
    dplyr::mutate(val = 1, ID = rownames(.)) %>%
# split variables to columns, replace NA with 0
    pivot_wider(names_from = ocean_proximity, values_from = val,
                values_fill = list(val = 0)) %>%
# drop column "ID"
    select(-ID)

cat_housing %>% colnames()

```

## rename columns name
```{r}

cat_housing <- cat_housing %>% 
  dplyr::rename(near_bay = "NEAR BAY")

cat_housing %>% colnames()

cat_housing %>% str()

```


## scale the numerical variables
```{r}
# drops = c('median_house_value')
# 
# housing_num =  housing[ , !(names(housing) %in% drops)]
# 
# housing_num %>% head()

# housing_num %>% str()


scaled_housing_num = scale(cat_housing)


scaled_housing_num %>% head()

scaled_housing_num %>% str()

housing <- as_tibble(scaled_housing_num)

write_csv(housing, "clean-housing.csv")

```

## splitting dataset to train & test
```{r}

# Set a random seed so that same sample can be reproduced in future runs
set.seed(23278) 

sample <- sample.int(n = nrow(housing), size = floor(.8*nrow(housing)), replace = F)

# train dataset
train <- housing[sample, ] # just the samples

# test dataset
test <- housing[-sample, ] #everything but the samples

```
## check for length of train + test = before splitting
```{r}
nrow(housing) == nrow(train) + nrow(test)

```

## predictive models test
```{r}

glm_house <- glm(median_house_value ~ median_income + mean_rooms + population, data = housing)

```

```{r}

k_fold_cv_error <- cv.glm(housing , glm_house, K = 5)

# raw cross-validation estimate of prediction error, adjusted cross-validation estimate.
k_fold_cv_error$delta
  
```

```{r}

glm_cv_rmse = sqrt(k_fold_cv_error$delta)[1]
glm_cv_rmse # about 72,384 ... it is a start

```

## what parts of the model are callable?

```{r}

names(glm_house)

```


```{r}
# we can say that of the three, median income had the biggest effect on housing price, but be careful and google lots before intrepreting coefficients!
glm_house$coefficients

```

## Random forest model
```{r}
?randomForest

names(train)

```

```{r}
set.seed(23278)

train_y = train[, 'median_house_value']
train_x = train[, names(train) != 'median_house_value']

train_y %>% head()
train_y %>% str()


train_x %>% head()

```

```{r}

head(train_x$med)

# rf_model = randomForest(train_x, y = train_y , ntree = 500, importance = TRUE)

# due to error Warning: The response has five or fewer unique values.  Are you sure you want to do regression?Error in randomForest.default(train_x, y = train_y, ntree = 500, importance = TRUE) :   length of response must be the same as predictors

# https://stackoverflow.com/questions/56943991/random-forest-error-message-response-has-five-or-fewer-unique-values

# train_y$median_house_value <- as.factor(train_y$median_house_value)

# still have the same error 
rf_model = randomForest(train_x, y = train_y , ntree = 500, importance = TRUE)

names(rf_model)

```




